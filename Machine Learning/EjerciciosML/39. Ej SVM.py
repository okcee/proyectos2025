''' Clasificar piezas industriales - Practicar con numpy para generar datos, con el algoritmo de m√°quinas de vectores de sporte (SVM) para realizar clasificaciones, con pandas y matplotlib para graficar los resultados

üéØ Objetivo general
Desarrollar un sistema autom√°tico de inspecci√≥n de calidad para piezas industriales usando aprendizaje autom√°tico. Para ello, implementar√°s varias clases en Python que simulan la creaci√≥n de datos, entrenan un modelo de clasificaci√≥n (SVM) y visualizan los resultados.
Este proyecto se validar√° con tests autom√°ticos, por lo tanto, las clases y m√©todos deben tener exactamente los nombres y firmas indicadas.

üì¶ Clases y m√©todos obligatorios
1. class Piece
Representa una pieza individual con sus caracter√≠sticas f√≠sicas y su etiqueta de calidad.
Constructor:
def __init__(self, texture, symmetry, edges, center_offset, label):
texture (float): Nivel de textura/homogeneidad (entre 0 y 1).
symmetry (float): Grado de simetr√≠a (entre 0 y 1).
edges (float): N√∫mero de bordes detectados.
center_offset (float): Desviaci√≥n del centro respecto al ideal.
label (str): "Correcta" o "Defectuosa".
M√©todo requerido:
def to_vector(self) -> list:
    # Devuelve [texture, symmetry, edges, center_offset]
2. class PieceDatasetGenerator
Genera una lista de objetos Piece simulando datos industriales con una l√≥gica de clasificaci√≥n basada en reglas.
Constructor:
def __init__(self, n=400):
n: n√∫mero de piezas a generar (por defecto 400).
M√©todo requerido:
def generate(self) -> list:
    # Devuelve una lista de objetos Piece, cada uno con su etiqueta calculada

üí° L√≥gica de generaci√≥n:
Cada caracter√≠stica se genera aleatoriamente seg√∫n distribuciones normales:

üîé Reglas de clasificaci√≥n:
Una pieza ser√° etiquetada como "Defectuosa" si cumple al menos una de estas condiciones:
symmetry < 0.4 y center_offset > 0.25,
o bien texture < 0.35,
o bien edges < 30,
o bien center_offset > 0.35.
En caso contrario, ser√° etiquetada como "Correcta"
3. class PieceClassifier
Entrena un modelo de clasificaci√≥n usando SVM y permite evaluar y predecir etiquetas de nuevas piezas.
Constructor:
def __init__(self):
M√©todos requeridos:
def fit(self, pieces: list) -> None:
    # Entrena el modelo SVM con una lista de objetos Piece
def predict(self, texture, symmetry, edges, center_offset) -> str:
    # Predice si una pieza con esas caracter√≠sticas es "Correcta" o "Defectuosa"
def evaluate(self, test_data: list) -> None:
    # Muestra matriz de confusi√≥n e informe de clasificaci√≥n (usa sklearn)
El modelo debe usar:
from sklearn.svm import SVC
SVC(kernel='rbf', gamma='scale', C=1.0)
4. class PieceAnalysisExample
Clase demostrativa que conecta todas las partes del proyecto y muestra un ejemplo completo de uso del sistema.
M√©todo requerido:
def run(self) -> None:
Este m√©todo debe realizar todo el flujo de trabajo del sistema:

‚úÖ Flujo completo requerido:
Generaci√≥n de datos:
Crear un objeto PieceDatasetGenerator (usar valor por defecto: 400 piezas).
Llamar a .generate() para obtener las piezas.
Divisi√≥n de datos:
Usar train_test_split de sklearn.model_selection.
Separar en 70% entrenamiento y 30% test.
Usar random_state=42.
Entrenamiento:
Crear un PieceClassifier.
Llamar a .fit() con los datos de entrenamiento.
Evaluaci√≥n:
Llamar a .evaluate() con los datos de prueba.
Mostrar matriz de confusi√≥n e informe de clasificaci√≥n.
Predicci√≥n personalizada:
Predecir la clase de una pieza con estas caracter√≠sticas:
(0.45, 0.5, 45, 0.15)
Mostrar por pantalla las caracter√≠sticas y el resultado predicho.
Visualizaci√≥n:
Crear un DataFrame con los siguientes campos:
"Textura", "Simetr√≠a", "Bordes", "Offset", "Etiqueta"
Crear un scatter plot:
Eje X: "Textura"
Eje Y: "Offset"
Colores: verde = "Correcta", rojo = "Defectuosa"
Agregar t√≠tulo: "üè≠ Clasificaci√≥n de piezas industriales"
Mostrar leyenda y rejilla

üéØ Ejemplo de uso
example = PieceAnalysisExample()
example.run()

Salida esperada
üìä Matriz de confusi√≥n:
[[87  0]
[28  5]]

üìù Informe de clasificaci√≥n:
                precision    recall  f1-score   support

    Correcta       0.76      1.00      0.86        87
  Defectuosa       1.00      0.15      0.26        33
 
    accuracy                           0.77       120
   macro avg       0.88      0.58      0.56       120
weighted avg       0.82      0.77      0.70       120

üîé Predicci√≥n de pieza personalizada:
    ‚Üí Textura: 0.45, Simetr√≠a: 0.50, Bordes: 45, Offset: 0.15
    ‚Üí Clasificaci√≥n: Correcta
'''

# Importamos las bibliotecas necesarias
import numpy as np # Para trabajar con arrays num√©ricos y generaci√≥n de datos aleatorios
import pandas as pd # Para facilitar la organizaci√≥n de datos, √∫til para la visualizaci√≥n
import matplotlib.pyplot as plt # Para crear gr√°ficos
from sklearn.model_selection import train_test_split # Para dividir el dataset
from sklearn.svm import SVC # El clasificador de M√°quinas de Vectores de Soporte (SVM)
from sklearn.metrics import confusion_matrix, classification_report # Para evaluar el modelo
from sklearn.preprocessing import StandardScaler # Para escalar las caracter√≠sticas, importante para SVM

# 2. Clase Piece: Representa una √∫nica pieza industrial
# Guarda sus caracter√≠sticas (atributos) y si es "Correcta" o "Defectuosa".
class Piece:
    # El constructor de la clase. Se llama al crear un nuevo objeto Piece.
    def __init__(self, texture, symmetry, edges, center_offset, label):
        self.texture = texture          # Textura de la pieza (flotante entre 0 y 1)
        self.symmetry = symmetry        # Simetr√≠a de la pieza (flotante entre 0 y 1)
        self.edges = edges              # Cantidad de bordes (entero)
        self.center_offset = center_offset # Desviaci√≥n del centro (flotante positivo)
        self.label = label              # Etiqueta: "Correcta" o "Defectuosa"

    # M√©todo para convertir los atributos en un formato vectorial (lista o array)
    # Este formato es el que los modelos de Machine Learning esperan como entrada (X).
    def to_vector(self):
        return [self.texture, self.symmetry, self.edges, self.center_offset]

    # M√©todo especial para representar el objeto como una cadena, √∫til para imprimirlo
    def __repr__(self):
        return f"Piece(texture={self.texture:.2f}, symmetry={self.symmetry:.2f}, edges={self.edges}, center_offset={self.center_offset:.2f}, label='{self.label}')"

# 3. Clase PieceDatasetGenerator: Genera el conjunto de datos simulado
# Crea un n√∫mero 'n' de piezas con caracter√≠sticas y etiquetas seg√∫n reglas predefinidas.
class PieceDatasetGenerator:
    # El constructor. Recibe 'n', el n√∫mero de piezas a generar.
    def __init__(self, n=400):
        self.n = n # Guarda el n√∫mero de piezas

    # M√©todo para generar las piezas y sus etiquetas
    def generate(self):
        np.random.seed(42) # Fija una semilla para que los resultados aleatorios sean los mismos cada vez que se ejecuta
        # Genera arrays de n√∫meros aleatorios para cada caracter√≠stica
        # Usamos distribuci√≥n normal con media y desviaci√≥n est√°ndar especificadas
        # 'size=self.n' asegura que cada array tenga 'n' elementos
        textures = np.random.normal(0.5, 0.15, size=self.n)
        symmetries = np.random.normal(0.6, 0.2, size=self.n)
        # Para los bordes, generamos n√∫meros, aseguramos que sean no negativos (clip) y los convertimos a enteros (astype).
        edges = np.clip(np.random.normal(50, 15, size=self.n), 0, None).astype(int)
        # Para el offset, generamos n√∫meros (media 0), tomamos el valor absoluto (np.abs) para que sean positivos.
        offsets = np.abs(np.random.normal(0, 0.2, size=self.n))

        data = [] # Lista para guardar los objetos Piece generados
        # Iteramos sobre las caracter√≠sticas generadas para crear cada pieza
        for t, s, e, o in zip(textures, symmetries, edges, offsets):
            # Aplicamos las reglas de clasificaci√≥n para determinar la etiqueta
            # Regla 1: Si simetr√≠a < 0.4 Y offset > 0.25 -> Defectuosa
            if s < 0.4 and o > 0.25:
                label = "Defectuosa"
            # Regla 2: Si textura < 0.35 O bordes < 30 O offset > 0.35 -> Defectuosa
            elif t < 0.35 or e < 30 or o > 0.35:
                label = "Defectuosa"
            # Si no cumple ninguna regla anterior -> Correcta
            else:
                label = "Correcta"
            # Creamos un objeto Piece con las caracter√≠sticas y la etiqueta, y lo a√±adimos a la lista
            data.append(Piece(t, s, e, o, label))

        return data # Devolvemos la lista de objetos Piece

# 4. Clase PieceClassifier: Implementa y gestiona el modelo SVM
# Se encarga de entrenar el modelo, hacer predicciones y evaluar su rendimiento.
class PieceClassifier:
    # El constructor. Inicializa el modelo SVM y el escalador.
    def __init__(self):
        # Inicializa el modelo SVC (Support Vector Classifier)
        # kernel='rbf': Un tipo com√∫n de kernel para SVM no lineal
        # gamma='scale': Determina la influencia de un solo ejemplo de entrenamiento. 'scale' es una opci√≥n com√∫n que usa 1 / (n_features * X.var())
        # C=1.0: Par√°metro de regularizaci√≥n. Controla el compromiso entre margen suave y clasificaci√≥n correcta de los puntos de entrenamiento.
        self.model = SVC(kernel='rbf', gamma='scale', C=1.0)
        # Inicializa el escalador de caracter√≠sticas.
        # StandardScaler centra los datos a media 0 y escala a varianza 1.
        # Esto es crucial para SVMs que son sensibles a la escala de las caracter√≠sticas.
        self.scaler = StandardScaler()

    # M√©todo para entrenar el modelo
    # Recibe una lista de objetos Piece (los datos de entrenamiento)
    def fit(self, pieces):
        # Extrae las caracter√≠sticas (X) de la lista de piezas
        # Cada p.to_vector() es una lista, np.array() las convierte en un array 2D (samples x features)
        X = np.array([p.to_vector() for p in pieces])
        # Extrae las etiquetas (y) de la lista de piezas
        # np.array() las convierte en un array 1D (labels)
        y = np.array([p.label for p in pieces])

        # Escala las caracter√≠sticas de los datos de entrenamiento
        # fit_transform: Calcula la media y desviaci√≥n est√°ndar de X, y luego transforma X.
        # El escalador APRENDE DE LOS DATOS DE ENTRENAMIENTO.
        X_scaled = self.scaler.fit_transform(X)

        # Entrena el modelo SVM con los datos escalados y sus etiquetas
        self.model.fit(X_scaled, y)

    # M√©todo para predecir la clase de una nueva pieza
    # Recibe los 4 atributos de la pieza
    def predict(self, texture, symmetry, edges, offset):
        # Crea un array NumPy 2D con los atributos de la √∫nica pieza
        # [[...]] crea una fila con las 4 columnas, formato esperado por transform y predict
        piece_vector = np.array([[texture, symmetry, edges, offset]])
        # Escala el vector de la pieza usando el escalador YA ENTRENADO con los datos de entrenamiento.
        # transform: Aplica la misma transformaci√≥n (usando la media y varianza APRENDIDAS) a los nuevos datos.
        piece_scaled = self.scaler.transform(piece_vector)
        # Realiza la predicci√≥n usando el modelo entrenado
        return self.model.predict(piece_scaled)[0] # [0] para obtener el resultado del array de una sola predicci√≥n

    # M√©todo para evaluar el rendimiento del modelo en un conjunto de prueba
    # Recibe una lista de objetos Piece (los datos de prueba)
    def evaluate(self, test_data):
        # Extrae caracter√≠sticas (X_test) y etiquetas verdaderas (y_true) de los datos de prueba
        X_test = np.array([p.to_vector() for p in test_data])
        y_true = np.array([p.label for p in test_data])

        # Escala las caracter√≠sticas de los datos de prueba usando el escalador ENTRENADO previamente.
        X_test_scaled = self.scaler.transform(X_test)

        # Realiza predicciones en los datos de prueba escalados
        y_pred = self.model.predict(X_test_scaled)

        # Imprime la matriz de confusi√≥n y el informe de clasificaci√≥n
        print("üìä Matriz de confusi√≥n:")
        # Muestra cu√°ntas piezas de cada clase real fueron clasificadas en cada clase predicha.
        # [[Verdaderos Correctos, Falsos Defectuosos], [Falsos Correctos, Verdaderos Defectuosos]]
        print(confusion_matrix(y_true, y_pred))
        print("\nüìù Informe de clasificaci√≥n:")
        # Proporciona m√©tricas clave (precisi√≥n, recall, f1-score, soporte) por clase.
        # target_names: Etiquetas de las clases para el informe.
        print(classification_report(y_true, y_pred, target_names=["Correcta", "Defectuosa"]))


# 5. Clase PieceAnalysisExample: Orquesta todo el proceso
# Aqu√≠ se llama a las otras clases para generar datos, entrenar, evaluar y visualizar.
class PieceAnalysisExample:
    # El constructor. Simple en este caso.
    def __init__(self):
        pass # No necesita inicializar nada aqu√≠

    @staticmethod
    def run():
        print("Generando dataset...")
        # Crea un generador y genera las 400 piezas
        generator = PieceDatasetGenerator(n=400)
        pieces = generator.generate()
        print(f"Dataset generado con {len(pieces)} piezas.")

        print("Dividiendo datos en entrenamiento y prueba...")
        # Divide la lista COMPLETA de objetos Piece en conjuntos de entrenamiento y prueba (70/30)
        # random_state: Asegura que la divisi√≥n sea la misma cada vez.
        # stratify: Mantiene la misma proporci√≥n de clases en ambos conjuntos.
        # Verificamos si hay al menos 2 muestras de cada clase para estratificar
        labels = [p.label for p in pieces]
        if len(set(labels)) < 2 or min([labels.count(l) for l in set(labels)]) < 2:
             print("Advertencia: No se puede estratificar por falta de muestras por clase. Usando divisi√≥n no estratificada.")
             train, test = train_test_split(pieces, test_size=0.3, random_state=42)
        else:
             train, test = train_test_split(pieces, test_size=0.3, random_state=42, stratify=labels)

        print(f"Tama√±o del conjunto de entrenamiento: {len(train)}")
        print(f"Tama√±o del conjunto de prueba: {len(test)}")

        print("Inicializando y entrenando clasificador...")
        # Crea una instancia del clasificador
        classifier = PieceClassifier()
        # Entrena el clasificador usando SOLO los datos de entrenamiento
        classifier.fit(train)
        print("Modelo entrenado.")

        print("Evaluando modelo en datos de prueba...")
        # Eval√∫a el rendimiento del modelo usando SOLO los datos de prueba (datos que el modelo no ha visto)
        classifier.evaluate(test)

        # Secci√≥n para probar una pieza personalizada
        print(f"\nüîé Predicci√≥n de pieza personalizada:")
        sample_piece_attrs = (0.45, 0.5, 45, 0.15) # Atributos de la pieza de ejemplo
        # Usa el m√©todo predict del clasificador para obtener la predicci√≥n
        # El *sample_piece_attrs desempaqueta la tupla en argumentos separados
        prediction = classifier.predict(*sample_piece_attrs)
        print(f"  ‚Üí Textura: {sample_piece_attrs[0]:.2f}, Simetr√≠a: {sample_piece_attrs[1]:.2f}, Bordes: {sample_piece_attrs[2]}, Offset: {sample_piece_attrs[3]:.2f}")
        print(f"  ‚Üí Clasificaci√≥n: {prediction}")

        # Secci√≥n de visualizaci√≥n de resultados
        print("\nVisualizando resultados (dataset completo)...")
        # Crea un DataFrame de pandas con todos los datos para facilitar la visualizaci√≥n
        df = pd.DataFrame({
            "Textura": [p.texture for p in pieces],
            "Simetr√≠a": [p.symmetry for p in pieces],
            "Bordes": [p.edges for p in pieces],
            "Offset": [p.center_offset for p in pieces],
            "Etiqueta": [p.label for p in pieces] # Usamos la etiqueta real para colorear
        })

        # Define un diccionario para mapear etiquetas a colores
        colores = {"Correcta": "green", "Defectuosa": "red"}

        # Crea una figura y ejes para el gr√°fico
        plt.figure(figsize=(8, 6))

        # Itera sobre las etiquetas y colores definidos
        for label, color in colores.items():
            # Filtra el DataFrame para obtener solo las piezas con la etiqueta actual
            subset = df[df["Etiqueta"] == label]
            # Crea un gr√°fico de dispersi√≥n (scatter plot) para este subconjunto
            # Eje X: Textura, Eje Y: Offset
            # c=color: Usa el color definido para la etiqueta
            # label=label: A√±ade la etiqueta para la leyenda
            # alpha: Transparencia de los puntos
            plt.scatter(subset["Textura"], subset["Offset"], label=label, c=color, alpha=0.6, edgecolors='w', linewidth=0.5) # edgecolors y linewidth mejoran la visibilidad de los puntos

        # Configura etiquetas de ejes, t√≠tulo y leyenda del gr√°fico
        plt.xlabel("Nivel de textura (homogeneidad)")
        plt.ylabel("Desviaci√≥n del centro de masa")
        plt.title("üè≠ Clasificaci√≥n de piezas industriales")
        plt.grid(True, linestyle='--', alpha=0.6) # A√±ade una cuadr√≠cula al gr√°fico
        plt.legend(title="Estado de la pieza") # Muestra la leyenda con los colores y etiquetas
        # Establece los l√≠mites de los ejes para una mejor visualizaci√≥n de los datos
        plt.xlim(0, 1)
        plt.ylim(0, 0.5)
        # Muestra el gr√°fico
        plt.show()

# 6. Ejecuta el ejemplo si el script se corre directamente
# Esto es una convenci√≥n en Python para hacer que el c√≥digo sea ejecutable.
if __name__ == "__main__":
    # Crea una instancia de la clase principal de ejemplo
    example = PieceAnalysisExample()
    # Ejecuta el proceso completo
    example.run()
